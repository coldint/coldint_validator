{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from regex import Regex\n",
    "import wandb\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "def get_all_runs() -> List[wandb.run]:\n",
    "    api = wandb.Api(timeout=100)\n",
    "    # By default, runs are sorted in descending order by creation time.\n",
    "    return api.runs(\n",
    "        f\"opentensor-dev/pretraining-subnet\",\n",
    "        # The regex matching is quite poor, so let's just match on anything any filter ourselves.\n",
    "        per_page=1000,\n",
    "    )\n",
    "    \n",
    "regex = r'validator-([0-9]{1,3})-2024-.*'\n",
    "filtered_runs = [r for r in get_all_runs()[:5000] if re.match(regex, r.name)]\n",
    "\n",
    "print(len(filtered_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import dataclasses\n",
    "from re import S\n",
    "import sys\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "import json\n",
    "\n",
    "\n",
    "def parse_to_nanos(duration: str) -> int:\n",
    "    # duration is formatted like: 1.23 ms or 2.123 min\n",
    "    units = {\n",
    "        \"ns\": 1,\n",
    "        \"μs\": 1000,\n",
    "        \"ms\": 1000_000,\n",
    "        \"s\": 1000_000_000,\n",
    "        \"min\": 60 * 1000_000_000,\n",
    "    }\n",
    "    tokens = duration.split(\" \")\n",
    "    assert len(tokens) == 2, f\"Unexpected duration format: {duration}\"\n",
    "    value = float(tokens[0])\n",
    "    unit = tokens[1]\n",
    "    return int(value * units[unit])\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class stats:\n",
    "    samples: int\n",
    "    min: int\n",
    "    median: int\n",
    "    max: int\n",
    "    p90: int\n",
    "\n",
    "def parse_summary_str(summary: str) -> ():\n",
    "    unit = r'(?:ns|μs|ms|s|min)'\n",
    "    matcher = rf'.*N=([0-9]+) \\| Min=([0-9\\.]+ {unit}) \\| Max=([0-9\\.]+ {unit}) \\| Median=([0-9\\.]+ {unit}) \\| P90=([0-9\\.]+ {unit})'\n",
    "    groups = re.match(matcher, summary).groups()\n",
    "    return stats(\n",
    "        samples=int(groups[0]),\n",
    "        min=parse_to_nanos(groups[1]) / 1000_000_000,\n",
    "        max=parse_to_nanos(groups[2]) / 1000_000_000,\n",
    "        median=parse_to_nanos(groups[3])/ 1000_000_000,\n",
    "        p90=parse_to_nanos(groups[4])/ 1000_000_000,\n",
    "    )\n",
    "\n",
    "regex = r'validator-([0-9]{1,3})-2024-.*'\n",
    "\n",
    "# Map of uid to timestamp.\n",
    "most_recent_runs = defaultdict(lambda: sys.maxsize)\n",
    "stats_by_uid = {}\n",
    "\n",
    "for run in filtered_runs:\n",
    "    uid = int(re.match(regex, run.name).group(1))\n",
    "    timestamp = json.loads(filtered_runs[0].summary['original_format_json'])[\"timestamp\"]\n",
    "    if timestamp < most_recent_runs[uid]:\n",
    "        if run.summary.get(\"load_model_perf_log\"):\n",
    "            load_stats = parse_summary_str(run.summary.get(\"load_model_perf_log\"))\n",
    "            eval_stats = parse_summary_str(run.summary.get(\"compute_model_perf_log\"))\n",
    "            stats_by_uid[uid] = (load_stats, eval_stats)\n",
    "            most_recent_runs[uid] = timestamp\n",
    "\n",
    "table = Table(title=\"Perf stats\")\n",
    "table.add_column(\"uid\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"samples\", style=\"magenta\")\n",
    "table.add_column(\"load_model_avg\", style=\"magenta\")\n",
    "table.add_column(\"load_model_max\", style=\"magenta\")\n",
    "table.add_column(\"eval_model_avg\", style=\"magenta\")\n",
    "table.add_column(\"eval_model_max\", style=\"magenta\")\n",
    "uids = sorted([int(uid) for uid in stats_by_uid.keys()])\n",
    "for uid in uids:\n",
    "    s = stats_by_uid[uid]\n",
    "    table.add_row(\n",
    "        str(uid),\n",
    "        str(s[0].samples),\n",
    "        str(s[0].median),\n",
    "        str(s[0].max),\n",
    "        str(s[1].median),\n",
    "        str(s[1].max),\n",
    "    )\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
